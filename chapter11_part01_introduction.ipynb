{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJntJYfdFoK7"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7YBB-aFoLB"
      },
      "source": [
        "# Deep learning for text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPaFYa57FoLC"
      },
      "source": [
        "## Natural-language processing: The bird's eye view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZWX2ds4FoLD"
      },
      "source": [
        "## Preparing text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS1BlYMAFoLD"
      },
      "source": [
        "### Text standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c-7yE24FoLE"
      },
      "source": [
        "### Text splitting (tokenization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkT9xu1TFoLE"
      },
      "source": [
        "### Vocabulary indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQNLqf9nFoLF"
      },
      "source": [
        "### Using the TextVectorization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KUaeACwiFoLG"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "class Vectorizer:\n",
        "    def standardize(self, text):\n",
        "        text = text.lower()\n",
        "        return \"\".join(char for char in text if char not in string.punctuation)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        text = self.standardize(text)\n",
        "        return text.split()\n",
        "\n",
        "    def make_vocabulary(self, dataset):\n",
        "        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n",
        "        for text in dataset:\n",
        "            text = self.standardize(text)\n",
        "            tokens = self.tokenize(text)\n",
        "            for token in tokens:\n",
        "                if token not in self.vocabulary:\n",
        "                    self.vocabulary[token] = len(self.vocabulary)\n",
        "        self.inverse_vocabulary = dict(\n",
        "            (v, k) for k, v in self.vocabulary.items())\n",
        "\n",
        "    def encode(self, text):\n",
        "        text = self.standardize(text)\n",
        "        tokens = self.tokenize(text)\n",
        "        return [self.vocabulary.get(token, 1) for token in tokens]\n",
        "\n",
        "    def decode(self, int_sequence):\n",
        "        return \" \".join(\n",
        "            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n",
        "\n",
        "vectorizer = Vectorizer()\n",
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "vectorizer.make_vocabulary(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary"
      ],
      "metadata": {
        "id": "RkBjkjAaFxSK",
        "outputId": "c18f8a66-28d1-4aba-a3a8-c86825f359cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '[UNK]': 1,\n",
              " 'a': 9,\n",
              " 'again': 6,\n",
              " 'and': 7,\n",
              " 'blooms': 11,\n",
              " 'erase': 4,\n",
              " 'i': 2,\n",
              " 'poppy': 10,\n",
              " 'rewrite': 5,\n",
              " 'then': 8,\n",
              " 'write': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt-g_WJRFoLJ",
        "outputId": "56a810c5-c650-4046-a561-37c1af2cac75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 5, 7, 1, 5, 6]\n"
          ]
        }
      ],
      "source": [
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = vectorizer.encode(test_sentence)\n",
        "print(encoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x6bAZeL9FoLJ",
        "outputId": "19ac191e-83c4-47c0-9e4f-8ba72da5b79b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "decoded_sentence = vectorizer.decode(encoded_sentence)\n",
        "print(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HMZs3sWXFoLJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lUZJdY9EFoLK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor)\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qMBWnkxYFoLK"
      },
      "outputs": [],
      "source": [
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMePh-k8FoLK"
      },
      "source": [
        "**Displaying the vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z0z39XITFoLL",
        "outputId": "d2b7a205-9913-4eda-8747-77fce6a090bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'erase',\n",
              " 'write',\n",
              " 'then',\n",
              " 'rewrite',\n",
              " 'poppy',\n",
              " 'i',\n",
              " 'blooms',\n",
              " 'and',\n",
              " 'again',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "text_vectorization.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hPLFM46aFoLL",
        "outputId": "517135e1-878c-4775-effc-dff4a669c812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7PgwaDWqFoLL",
        "outputId": "75f59813-f072-46b9-8434-2503398965ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "inverse_vocab = dict(enumerate(vocabulary))\n",
        "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
        "print(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverse_vocab"
      ],
      "metadata": {
        "id": "Aka2kFwSGoA8",
        "outputId": "4824126c-329e-4912-e7f2-96ef22911d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '',\n",
              " 1: '[UNK]',\n",
              " 2: 'erase',\n",
              " 3: 'write',\n",
              " 4: 'then',\n",
              " 5: 'rewrite',\n",
              " 6: 'poppy',\n",
              " 7: 'i',\n",
              " 8: 'blooms',\n",
              " 9: 'and',\n",
              " 10: 'again',\n",
              " 11: 'a'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpFoQhjaFoLL"
      },
      "source": [
        "## Two approaches for representing groups of words: Sets and sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coLhax-uFoLM"
      },
      "source": [
        "### Preparing the IMDB movie reviews data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CL6-pvYSFoLM",
        "outputId": "6cae74da-156c-4f17-d827-31a1bb246e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  58.9M      0  0:00:01  0:00:01 --:--:-- 58.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PLuqfdPhFoLM"
      },
      "outputs": [],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DzGMXFs-FoLM",
        "outputId": "2de2b7ad-6703-4bbb-eba6-37349cb489ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('aclImdb')"
      ],
      "metadata": {
        "id": "B0ToEUyoHAYu",
        "outputId": "29773141-d7df-4577-ec77-a5629451684e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'README', 'val', 'imdbEr.txt', 'test', 'imdb.vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CsKGYbWDFoLN"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xb6MusbgFoLN",
        "outputId": "0d933a06-95c3-4973-b08b-710a356b8f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnvPiVHkFoLN"
      },
      "source": [
        "**Displaying the shapes and dtypes of the first batch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Mbwwv32NFoLN",
        "outputId": "172e8ca1-aaca-414e-c6a1-9cccb3c2269f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"Salvage is the worst so called horror film I've ever seen. There is nothing remotely horrific about it. It doesn't deserve to be in a genre so fine. First of all i don't see how so many people can think this piece of crap such a great movie. If I wrote something as boring and utterly ridiculous as this i would be laughed at and too embarrassed to subject others to the stupidity of it. Second: the acting is terrible and the lead actress is excruciatingly ugly. Third: the story sucks, its been used before, and the excuse that its a cheap movie is no excuse. Read the summery on the back of the case, it reveals the whole story. I do not recommend that you watch this movie unless you have 80 minutes to waste on something that will leave you regretting that you watched it. I feel really bad for those Crooks and the irony of their name. All hail Anthony Perkins!!!!!!!!!\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFYr8nuhFoLN"
      },
      "source": [
        "### Processing words as a set: The bag-of-words approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiAQFm3OFoLN"
      },
      "source": [
        "#### Single words (unigrams) with binary encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAnpxSLbFoLO"
      },
      "source": [
        "**Preprocessing our datasets with a `TextVectorization` layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VJwdiNdcFoLO"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,y in train_ds.take(1):\n",
        "    print(i)\n",
        "    print(y)"
      ],
      "metadata": {
        "id": "C3ofrIh5H0Jt",
        "outputId": "f90249ff-1f86-4279-e215-7b120f9aaed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"Unbelievably bad acting, a no good, unclear story and flashy images and slow-motions where they are needed the least: Adrenaline is everything a movie should not be.<br /><br />Georgina Verbaan (a so-and-so dutch soap actress who hasn't attended her English classes) plays rich girl Freya, who has the habit of 'thrill-seeking'. Which basicly is doing dangerous stunts, break stuff and annoy people. And not in a fun Jackass way. Then there's Dracko (Rivas). He kinda leads the bunch but has other illegal activities on the side. Then there's Freya's dad (Lockyer), who plays a dubious role as well. And, in the end, we got Jason (debutant Fyall), the boyfriend of Freya.<br /><br />One day, Freya gets disappeared and everybody seems involved but we, the viewer really don't care as nobody of the cast is either likable or believable, and the story doesn't make any sense.<br /><br />Why was this even made? 2/10.\"\n",
            " b'Clocking in at an interminable three hours and twenty minutes, \"Salaam-e-Ishq\" is a pretty but superficial comic soap opera from India that regales us with six interwoven tales of romantic love (which is at least four tales too many in my estimation).<br /><br />Filmed like a cross between an MTV music video and a Super Bowl beer commercial, the movie is a sprawling mishmash of exotic settings, dazzling colors, sexy showgirls, high-stepping song-and-dance numbers, dream and fantasy sequences, winking character asides, corny dialogue and way-over-the-top comical performances - all pretty much standard-issue stuff when it comes to Bollywood happenings these days. It\\'s an exhausting chore just trying to keep all the characters straight as they dance, prance and preen their way through the incomprehensible storyline.<br /><br />There\\'s plenty for the viewer to feast his eyes on here - not least of all all the drop dead gorgeous women - but he\\'ll need the patience of Job to get him all the way through it.'\n",
            " b\"Unremittingly bleak and depressing, the film evokes as well as could be desired the legendary misery and emptiness that characterised Houellebecq's controversial novel of the same name. Like many French films, its manner is one of wistful profundity but it is painfully slow - or should that be, slowly painful? While this is an excellent and challenging film, it is not an enjoyable one and its difficult to think of any time when one might be in the 'right' mood to see it.\"\n",
            " b'This was one of the lamest movies we watched in the last few months with a predictable plot line and pretty bad acting (mainly from the supporting characters). The interview with Hugh Laurie on the DVD was actually more rewarding than the film itself...<br /><br />Hugh Laurie obviously put a lot of effort into learning how to dance the Samba but the scope of his character only required that he immerse himself at the kiddie end of the pool. The movie is based on the appearance of a lovely girl and great music but these are not sufficient to make good entertainment.<br /><br />If you have never seen Rio, or the inside of a British bank, this film is for you. 2 out of 10.'\n",
            " b'THE RINGMASTER stars Jerry Springer as a TV talkshow host called Jerry , but it`s not THE JERRY SPRINGER SHOW , his guests are trailer trash , but not the trailer trash you get on THE JERRY SPRINGER SHOW, they attack one another , but not like on.....What is the point of making a movie about THE JERRY SPRINGER show and pretending it`s not THE JERRY SPRINGER SHOW ? And on top of that this is a very boring film'\n",
            " b\"What can I say, it's a damn good movie. See it if you still haven't. Great camera works and lighting techniques. Awesome, just awesome. Orson Welles is incredible 'The Lady From Shanghai' can certainly take the place of 'Citizen Kane'.\"\n",
            " b\"This is still the benchmark to judge all Golden Age whodunnits by, and taking into account the limited technology and dubious ethical standards of the authorities (on screen) bears up well against all generations of similar attempts since on film and TV. Fast and furious with plenty of Warner Bros wipes, and thankfully no time for a love interest it gallops along, taking the splendid cast with it to the violent end. I never understood why the DA had to trail Vance around everywhere, I always thought they were deskbound. Palette as the detective but especially Girardot as the doctor are delightfully eccentric and un-PC - when glancing over the second murder victim he sniffs that there were too many people in the world anyway. Of course it is William Powell as Philo Vance (and Michael Curtiz as director) that makes the film what it is - when did Powell ever make a dud?<br /><br />The army of cops at the crime scene didn't really do a very good job in finding the second dead body and unconscious dog did they! The best bit is where Vance narrates to us all the sequence of events surrounding the murders - dodgy model sets combine with fantastic roving camera angles to produce a very modern feel, and startling with what has gone before. The only problem is as usual the conclusion can't match the overall deductive processes displayed throughout and a somewhat contrived ending is invoked; some Chan's, Moto's and many others of course could only be concluded this way too. But because it happens so fast and is ... slightly dubious morally it doesn't lessen my opinion of KMC's status as a classic!<br /><br />All the prints I've ever seen of KMC are (at worst) like looking into a goldfish bowl, so if you're interested in seeing it bear with it until you're sucked in.\"\n",
            " b\"This is the most ludicrous and laughable thriller I've ever seen. Oh....where to start....<br /><br />Plot (what little there is): Clayton Beresford Jr. (Hayden Christensen), a young billionaire, with a bad heart is desperately in need of a transplant. Clay has been secretly engaged to his mother's PA, Samantha, played by Jessica Alba. On the night that these two secretly get married, it just so happens that a heart donor with the same rare blood type is found. Go and figure the odds of that one! Once on the operating table, Clay finds out the anesthesia isn't working, and he can feel everything and hear everything.<br /><br />Fortunately Clay seems to be able to filter out the pain of a razor sharp scalpel cutting open his chest by simply concentrating on his memories of Samantha, which we are told he's doing through an annoying voice-over which never seems to stop.<br /><br />If you didn't burst out in laughter yet, you will surely start to when you see the surgical scenes. <br /><br />How could a young billionaire agree to have a heart transplant performed by one surgeon, one nurse, an attending physician and an drunk anesthesiologist? There were more people in the room when my wisdom tooth was getting pulled. Not to mention the medical behavior, which is too preposterous to be taken seriously...the operating room isn't even kept sterile...people are practically able to just walk in and out of the room without even having washed up... During the operation the viewer gets to hear Clay's thoughts, none of which are too fascinating. Ah...but here's what it's all about ...the doctors are trying to kill him in order to take his money. Believing him to be unconscious, the villains speak freely. Gosh! What will happen? <br /><br />Well... at least there's no interference from anyone else in the hospital, while an incompetent doctor who's got four malpractice lawsuits running against him is performing major heart surgery. Not even Clay's overprotective mother seems to be able to check on his status. The only one interested in keeping updated is Samantha...but oh no...could sweet Sam be in on it....You'll quickly find out through some Scooby Doo dialog...<br /><br />In the end, it wouldn't even matter whether or not Clay underwent anesthesia awareness, because the end would have turned out the same way in both cases.<br /><br />If you can ignore the feeling that the director/writer is trying to make fun of the patients who fell victim to anesthesia awareness, maybe there's some dumb fun to be had...<br /><br />Enjoy...\"\n",
            " b\"Shamefull as it may be, this movie actually made it to the videomarket, bringing shame on my proud country - any attempt to watch this movie without stopping or pausing, will be a fruitless attempt. one cannot bear to see more than one hour of this, then having either fallen asleep, or visited the bathroom for puking.<br /><br />Note: if you haven't seen anything else from Denmark, please remember this:<br /><br />some things were never meant to be - but still some idiot goes ahead and makes it anyway!\"\n",
            " b'There may be spoilers!<br /><br />Charlie Fineman (Adam Sandler), who lost his family in a tragedy, (the terrorist attacks of Sept. 11), still grieves over their deaths. He runs into his former college roommate, Alan Johnson (Don Cheadle), and the two rekindle their friendship. Alan vows to help his old friend come to terms with the terrible loss. This is a simplification of the basic story of Reign Over Me. <br /><br />This movie is, however, a story of how fate intercedes in our lives when we ourselves may be powerless do any thing about our own states of being. Alan is stuck in a life that he knows is no longer fulfilling. He feels friendless and out of touch with his own reality. He is unable to communicate with his wife and his associates at work. He can\\'t express his feelings and as a result feels lost and distant from his own world. He chances upon Charlie on the streets of Manhattan while driving from his job. Eventually he meets and discovers that Charlie, (who originally does not remember Alan), is living in a false reality of his own. Charlie has gone back to a time in his life when he had no family. He lives as if he were still a student playing in a rock band, collecting vinyl records of the 60s and 70s bands, and playing video games. He has escaped to a better and safer time in his life where there are no bad guys and he has a lot less to lose. Everyone in this movie is affected in some way by the tragedy that has affected Charlie and his remission to a formerly different and better (?) place. His landlady is his protector and great enabler. His in-laws are subtracted from his life because they would take him back to the reality that his family is now gone from his life. And Alan is most affected by him because Alan wants to, (in at first a selfish desire to escape from his own reality) to be with Charlie as a means to subtract himself from his own stifled reality and then he wants to find a way to help Charlie begin to recover from his self-induced guilt and denial of loss. It is through this relationship that not only is Charlie able to begin to heal himself but that Alan, in fact, learns to communicate and sate his true desires with his associates at work and, eventually, is able to admit to his wife he has not been able to communicate his real feelings to her but that he strongly wants to because he does love her. It is in fact a poignant moment in the film when the stuff has hit the fan and Charlie is being confronted with the reality of being put away that he and Alan are talking about the situation together over \"Chinese\" that Charlie states that he is in fact worried about Alan and not himself. <br /><br />This movie will, if you let it, take you through a river of emotions and leave you thinking. It will have you laughing at how Charlie uses his words, like people really do in everyday life, to make a comical statement of fact about a real situation. It will leave you on the verge of tears, (in my case actual tears), when Charlie confronts his grief and begins to come to grips with his tremendous loss. And that in fact the tragic reality is his guilt and loss has really never left him and he dealt with it in the only way he knew: denial. It will make you curse at the cold, unthinking actions of a young prosecutor trying to win his \"case\", (as I actually did at Charlie\\'s hearing!) And it will make you smile at the commonsense of a old and wise, stern judge, (Donald Sutherland who is great at his short distinct role and gives the best performance of a wise, stern person in the legal profession since Wilford Brimley played an Assistant Attorney General in Absence of Malice.)<br /><br />This movie was also amazing to me for a few other reasons: (1) I never looked at my watch once during the showing of the film. Which means it had me from the beginning to the end, (2) Although the cast was interracial, this fact was not important to the playing out of the roles of the characters in the film. Race was a non-factor to the performance of the roles in this movie. Amazing people can actually interact with out this fact being brought out! and (3) the only real reference to 9/11 is when Charlie\\'s financial attorney refers to the tragedy of Charlie\\'s loss as \"\\xc2\\x85what Charlie had become on 9/12\". Time will be the true test of how this movie will stand out in the future but if the purpose of a movie is not to just entertain but to make one think and have that movie stay with you long after you leave the theatre then Reign Over Me succeeded phenomenally as far as I am concerned. I have not yet forgotten this wonderful thought provoking film and I will wait impatiently for the day I can purchase it as a DVD.'\n",
            " b'Many of the classic films of the late \\'60s haven\\'t retained their ability to disturb and confront the audience. \"In Cold Blood\" hasn\\'t lost an ounce of its power. Its exceptionally well made yet forces the viewer to think. Some have complained not only about the film, but about Truman Capote\\'s source \"non-fiction novel\", that the central message is unsubtle. That may be true, but this is definitely a case where the lack of ambiguity doesn\\'t detract from the film at all. Its refreshing, especially considering today\\'s simplistic and manipulative moral dramas, to see a film with a convinced political voice unafraid to force the audience to consider its viewpoint. To be honest, I\\'m not sure if I agree with the film\\'s central message, but I admire its audacity nonetheless.<br /><br />Even if you disagree with the anti-capital punishment message, there\\'s plenty to admire about the film. The acting from the two leads is terrific. Scott Wilson (still one of the most underrated actors ever) is chilling as the nihilistic leader, one who uses his charisma to hide his weaknesses. Robert Blake is also chilling as the more submissive of the two and the one with a conscience. His character obviously has a voice of reason, but is terrified to go against Wilson (theres a good amount of homoerotic subtext on his character\\'s part). The cinematography is terrific, sleek yet gritty and really giving the impression the viewer is watching a documentary. Add another classic score from Quincey Jones, and you have a masterpiece. (9/10)'\n",
            " b\"Much about love & life can be learned from watching the folks at THE SHOP AROUND THE CORNER.<br /><br />Ernst Lubitsch had another quiet triumph added to his credit with this lovely film. With sparkling dialogue (courtesy of his longtime collaborator Samson Raphaelson) and wonderful performances from a cast of abundantly talented performers, he created a truly memorable movie. Always believing in playing up to the intelligence of his viewers, and favoring sophistication over slapstick, the director concocted a scintillating cinematic repast seasoned with that elusive, enigmatic quality known as the \\xc2\\x91Lubitsch touch.'<br /><br />Although the story is set in Budapest (and there is a jumble of accents among the players) this is of no consequence. The beautiful simplicity of the plot is that any great American city or small town could easily be the locus for the action.<br /><br />Jimmy Stewart & Margaret Sullavan are wonderful as the clerks in love with romance and then with each other - without knowing it. Their dialogue - so adeptly handled as to seem utterly natural - perfectly conveys their confusion & quiet desperation as they seek for soul mates. Theirs is one of the classic love stories of the cinema.<br /><br />Cherubic Frank Morgan has a more serious role than usual, that of a man whose transient importance in his little world is shattered when he finds himself to be a cuckold. An accomplished scene stealer, he allows no emotion to escape unvented. Additionally, Morgan provides the film with its most joyous few moments - near the end - when he determines that his store's newest employee, an impoverished youth, enjoys a memorable Christmas Eve.<br /><br />Joseph Schildkraut adds another vivid depiction to his roster of screen portrayals, this time that of a toadying, sycophantic Lothario who thoroughly deserves the punishment eventually meted out to him. Gentle Felix Bressart has his finest film role as a family man who really can not afford to become involved in shop intrigues, yet remains a steadfast friend to Stewart.<br /><br />Sara Haden graces the small role of a sales clerk. William Tracy is hilarious as the ambitious errand boy who takes advantage of unforeseen developments to leverage himself onto the sales force.<br /><br />In tiny roles, Charles Halton plays a no-nonsense detective and Edwin Maxwell appears as a pompous doctor. Movie mavens will recognize Mary Carr & Mabel Colcord - both uncredited - in their single scene as Miss Sullavan's grandmother & aunt.\"\n",
            " b'After Chicago, I was beginning to lose all respect for Richard Gere and then along came The Flock. There\\'s just so far a nice smile and a couple of stock facial gestures can get you, but he proved to me that he\\'s finally gotten hold of his craft and can act with the best of them. Clare Danes was also super as his \"trainee/replacement\". Some have suggested there was too much unnecessary violence, but I don\\'t see it that way. Nothing I saw detracted from the power of this film. I was really shocked I hadn\\'t heard of it being released in theaters and came across it at Blockbuster instead. Really an exceptional film with just the right blend of action, suspense, thrills, and social consciousness. As good as 7even? Well, maybe. And you\\'ll see better acting out of Gere than anyone\\'s ever gotten out of Pitt.'\n",
            " b\"Red Rock West is a perfect example of how good a film can be with practically no budget. All you need is a smart script, good actors and loads of atmosphere. RRW delivers all these and more.<br /><br />Nic Cage plays an ex-marine, injured in Lebanon, who is down to his last 5 dollars after being refused a job on an oilfield because of his bad knee. He roles into Red Rock and is mistaken by bartender Wayne (JT Walsh, not quite as his most menacing-but still evil) for a hit-man from Texas.<br /><br />He pays him to kill his wife and make it look like burglary. Only when he gets there, just to check her out. She offers him double to kill Wayne. Cage just wants to get the hell out of town with his free money and leave the sparring lovers be. But a series of mishaps and setbacks results in him yo-yoing in and out of Red Rock, back and forth. Eventually this leads to a run-in with Lyle from Dallas (a cheeky and somehow sympathetic Dennis Hopper), the REAL hit-man from Texas who offers to help without knowing he's making the plot more complicated.<br /><br />RRW never had a big release, thus most of it's audience discovered it on video or on cable TV showings. Viewing it in such a way might make it seem like a TV movie but it's bigger than that. The slick, slowly-timed direction, moody score and howling desert wind would have all made for a great movie in theatres but the best you can do these days is watch the DVD on a big HDTV.<br /><br />The only weak point of the movie I can think of is Lara Flynn Boyle's boring femme fatale with the nasty dyke-ish hairdo. I certainly wouldn't fall for her but if you assume that Nic Cage's character is in to militant lesbians then you'll accept it nonetheless.\"\n",
            " b\"I really liked ZB1. Really, I did. I have no problem with extremely low-budget movies, and I have enjoyed movies with worse production values than ZB3 (if you can imagine such a thing. check out 'wiseguys vs. zombies,' if you're interested). Indeed, I prefer lower budget zombie films, because I am suspicious that Hollywood directors do not understand what zombies are 'about.'<br /><br />But ZB3 was just so bad. It was retarded. I don't want to bother being dignified in my criticism. I want my 90 minutes back, etc. Except that it really only took ~80 minutes, because partway through I put it into 1.4X fast forward.<br /><br />Okay, here's some criticism.<br /><br />1. The pacing was TERRIBLE. Everyone talked in monologues. Even when someone just had a single line, the camera work and the editing and the insertion of a bunch of F-bombs into every sentence made the line FEEL like a monologue. At first I was excited about the 90 minute running time compared to ZB1's 70 minutes, but there were actually fewer 'events' in ZB3. It's all talking.<br /><br />2. The gore effects got stupider. Just glop rubbed around on people's tummies.<br /><br />3. Despite the epic exposition, there really wasn't a plot. And the exposition is indeed epic! I won't spoil it, if you're going to watch it. (Don't watch it.) But then, it's just a bunch of lame characters walking around and bickering for ~80 minutes. or fewer, if you so choose.\"\n",
            " b'This show is possibly the biggest, ugliest, most generic steam pile I\\'ve seen in children\\'s programming that\\'s actually become successful. The lead character, Johnny, while I understand he\\'s supposed to represent an ordinary kid, isn\\'t likable or even tolerable. The jokes are lame, overdone (i.e. the \"Whoa! Didn\\'t see that coming\" gag. Come on, that wasn\\'t even funny the first time. It\\'s not even cute) and lack any form of primitive wit or inspiration. And lastly... it\\'s just plain ugly to look at. While kids aren\\'t especially critical of artistic talent, they still prefer eye candy. I can\\'t stand watching the show, because in a way, the art style is just...gross. Hideous, in fact. Just plain crummy. <br /><br />I just can\\'t stand that this is getting so much airtime. While I understand that nostalgia can be a little irrational and I shouldn\\'t be getting my hopes up on it coming back... I really miss the old cartoons. Bring back Dexter\\'s Laboratory, The Powerpuff Girls... anything but this crap. I guess it\\'s just wishful thinking though.<br /><br />Simply put, I advise you don\\'t waste your time on this show. I believe that truly good cartoons are able to be enjoyed by the big kids, too. And this doesn\\'t cut it.'\n",
            " b'This is by far my favorite film of all time. That\\'s mainly because it\\'s not afraid to delve into some very politically incorrect topics (such as spanking and female submissiveness) that other mainstream films are just too timid to touch. Nothing seems to be off-limits in this film as the director freely develops the story without any concern given to possibly offending the viewer. However, I don\\'t think anything was done here purely for shock value or to purposely offend anyone. Sean Young turns in an excellent and courageous performance. Most established mainstream actresses would not have taken on this role or would have asked for some major script changes before accepting it. The other cast members do a fine job as well.<br /><br />Have you noticed that this movie hasn\\'t appeared on pay cable since an obligatory brief run a year after it hit the theaters? Have you ever wondered why? The obvious reason is that it just doesn\\'t fit today\\'s political atmosphere. It seems quite ironic to me that some premium channels now carry softcore porn (that\\'s getting closer and closer to hardcore porn) but will not carry a mainstream movie like \"Love Crimes\". Sadly, even though this movie is only 11 years old, it could probably not be made today.<br /><br />'\n",
            " b\"This movie wasn't just bad - it was terrible. After I watched it, I actually felt the need to TAKE A SHOWER to get the filth off of me. There is running 'gag' with an elderly couple making out, it is not funny, but it is disgusting. The monster make up was cool, but that is all. The continuity errors alone will have you angry - at least I was. The editing is really poor.<br /><br />Almost anything else you could possibly do would be better than spending time watching this movie. Even if your group of friends are into 'bad movies' this one is exceptional in its ineptitude, I couldn't even bring myself to laugh at it. You have been warned.\"\n",
            " b\"I grew up during the time that the music in this movie was popular. What a wonderful time for music and dancing! My only complaint was that I was a little too young to go to the USO and nightclubs. Guess it sounds like I'm living in the past, (I do have wonderful memories)so what's wrong with that?!!? World War 2 was a terrible time, except where music was concerned. Glenn Miller's death was a terrible sadness to us. This movie will be a favorite of mine. Clio Laine was excellent; what a voice! I don't know how I ever missed this movie. My main reason for this commentary is to alert the modern generation to an alternative to Rap and New Age music, which is offensive to me. Please watch this movie and give it a chance!\"\n",
            " b'REVOLT OF THE ZOMBIES (2 outta 5 stars) No, this is not a long-lost ancestor to the classic George A. Romero zombie flicks. This is a low-budget potboiler from 1936 that probably seemed very cool to audiences of the time... but seems awfully routine these days. There is actually a pretty good scene at the start of a soldier firing off his pistol into a horde of approaching zombie soldiers... and a close-up of bullets entering the bare chest of one of them. The effect looks hopelessly fake these days but in 1936 I\\'m sure it had audiences gasping. The story concerns the search for the secret of mind control... ostensibly to create an unstoppable zombie army... but later as a means for one character to win the woman he loves. The movie is barely an hour long but moves at a snail\\'s pace so it seems feature-length, believe me! There really isn\\'t much to recommend it... you may get some amusement from the faked studio shots of the star \"wading\" through a \"swamp\". The ending is interesting... so I\\'d say the movie is worth seeing at least once. More than likely you will see it as an extra feature on some cheap \"4 movies on 1 DVD\" compilation at Wal-Mart for five bucks. Hey, it\\'s well worth the money...'\n",
            " b'Some of the best movies that are categorized as \"comedies\" actually blur between comedy and drama. \"The Graduate\" and \"Butch Cassidy and the Sundance Kid\", which were made also in the late 1960\\'s are perfect examples. Are they comedies with dramatic undertones, or dramas with a lot of humor? In many respects, \"The Odd Couple\" falls into this same category of being both comedy yet highly dramatic with deep underpinnings about human nature. Much of what happens may be funny to the audience but the characters are not laughing.<br /><br />Despite the rather light-hearted TV show of the 1970\\'s, the original \"Odd Couple\" is not merely about a neat guy and messy guy who are forced to live together because of their marital situation. It\\'s really about two opposites who must face why their marriages fell apart and how their detrimental idiosyncrasies reveal themselves outside of their marriage. Neatness, the characteristic of Felix Ungar (Jack Lemon perfectly cast) and messiness, the characteristic of Oscar Madison (Walter Matthau), are only the beginning and somewhat superficial. As the story unfolds, we find there is a lot more to these men than simply neatness versus messiness.<br /><br />Briefly, the story is really about Felix Ungar, who has to face an impending divorce from his wife Francis, who we never meet but is an important character throughout the story. On the verge of suicide, Ungar goes to the only place he knows: the apartment of Oscar Madison where a group of poker buddies hang out every so often. We learn that Ungar is not only a member of this \"poker club\" but the group knows what\\'s happening to him and try, in their inept way, to help out. Madison figures the best way to help Ungar is to let him move in with him until his suicidal tendencies wear off.<br /><br />Unfortunately for Madison, he doesn\\'t know what he\\'s getting himself into. Madison is a carefree happy-go-lucky if rather irresponsible slob who\\'s refrigerator was last cleaned probably when Herbert Hoover was still in the White House. Madison\\'s idea of serving snacks is grabbing moldy cheese and sticking them in between two pieces of bread, and then throwing the contents of a bag of chips on the table. On the other hand, he enjoys booze and women, in short having a good time. <br /><br />Ungar is not only altogether different, he is diametrically opposite. He is not only an obsessive neatness nut that finds more joy in disinfecting the apartment than meeting women but he knows more than most women do about cooking and fine eating. At one point, he calls his ex-wife, not to talk about reconciling, but to get her recipe for meatloaf. At another moment, Ungar was going to spend the rest of the evening cutting cabbage for coleslaw. When Madison seems unimpressed, Ungar finally confesses he was only doing it for his roommate because he can\\'t stand coleslaw. Who is this guy? But he has another endearing trait: Felix is also a hypochondriac. He obsesses about his health to the point where he makes strange noises in public places claiming he\\'s helping his sinuses. He seems to have every health condition in the book. And if they made up more, Felix would probably have them. Ultimately, he is overly self-absorbed.<br /><br />Running throughout the movie are references to marriage. At one point when Madison is trying to convince Ungar to move in, he says, \"What do you want, a wedding ring?\" But little does he know that it is not the neat guy who can\\'t deal with the messy guy, but the other way around. Their friendship becomes an inadvertent hellish relationship. And the climax occurs when Oscar invites two lonely British sisters for a get-together with both comedic and tragic results. This is one of the best comedies of its type ever written and not to be missed, with superlative performances by Walter Matthau and Jack Lemon in roles that are hard to imagine better played by anyone else. It is unfortunate that writing of this caliber is sadly lacking from most comedies being produced today.'\n",
            " b\"Who did the research for this film? It's set in Baghdad in 2004, however all the Soldiers are wearing ACUs and have all Universal Camouflage Pattern gear. No one was wearing that stuff in 04. <br /><br />I just saw this film while deployed overseas and I can say that the overwhelming feeling from the audience was WTF? This movie made no sense, had characters come and go with no explanation, and people doing ridiculous things that would NEVER happen in real life. I realize that it's a movie, but it's obviously trying to portray something realistic. It fails miserably, but it's trying. <br /><br />It's like someone came up with a bunch of random ideas, chewed them up and swallowed, then vomited out a film. I would not recommend this film to anyone. I'm still not sure why I sat through the whole thing. GI Joe was one that really made you think compared to this. STAY AWAY!\"\n",
            " b\"This movie is actually worse than most movies I've ever suffered through, and I've suffered through a lot. Absolute nonsense. It's got terrible, forced dialogue; pointless plot developments; really drawn out 'spooky imagery' scenes, which look more like a high school remedial art project than a horror movie; 5/10 at best attractive women; long, boring sex scenes involving said women (forget what you know about virgins! especially ones with lop- sided fake breasts); muttered, difficult to understand speech from some of the characters; and they actually used the masks from Killer Klowns from Outer Space during a masturbation scene, which should be a saving grace because that movie was pretty funny, but it isn't. Veden Fell is the lamest bad guy in the history of film. <br /><br />Absolutely give this one a miss.\"\n",
            " b\"Lorenzo Lamas stars as Jack `Solider` Kelly an ex-vietnam vet and a renegade cop who goes on a search and destroy mission to save his sister from backwoods rednecks. Atrocious movie is so cheaply made and so bad that Ron Palillo is third billed, and yet has 3 minutes of screen time, and even those aren't any good. Overall a terrible movie, but the scenes with Lorenzo Lamas and Josie Bell hanging from a tree bagged and gagged are worth a few (unintentional) laughs. Followed by an improved sequel.\"\n",
            " b'Jack Black can usually make me snicker simply by breathing, but in this movie...<br /><br />Besides the direction, writing, lack of plot, constant mugging (aided and abetted by constant straight-on camera shots), and a .050 joke batting average, it was still an utter waste of time. The idea sounds promising, but what potential there was gets wasted with an utter lack of comedy and some of the worst direction I\\'ve seen this side of you-tube.<br /><br />I kept hearing that this film portrayed Mexicans very negatively. While that\\'s no doubt true, I really don\\'t think this movie is meant to be racist. I think that\\'s it\\'s more a result of a \"creative\" team desperately trying to find something funny in this mess. You can almost hear them crying out from behind the camera: \"Hey look, it\\'s an ugly Mexican! Laugh, people! Please, for the love of all things tenacious, LAUGH!\"<br /><br />But put the racism charges aside. When you get down to it, it\\'s anyone who plunked down good money and time to watch this pile of leftover refried beans that should be offended, IMO.'\n",
            " b'Does anyone know the exact quote about \"time and love\" by George Ede aka, Father Fitzpatrick in the move, It had to be you? He was talking to Charlie and Annna in the church as they were leaving? If not I will have to rent the movie. This was a great movie. I also loved Serendipity! Great love story for the soul! <br /><br />I met my one true love (my Soulmate) and although I had the experience to meet him when I had least expecting it, I wasn\\'t ready for that kind of emotional relationship. <br /><br />Altho, we did marry, I wasn\\'t mature enough to give as much as I thought I would. I got complacent and took his love for granted and he withstood it for 7 years. <br /><br />He finally left with resentment but we are still hurt and angry & in disbelief about the way it turned out. I had some very hard lessons to learn and we have now been apart 3 years.<br /><br />This movie meant a lot because I am still waiting on reconciling with my one and only true love. I can NOW appreciate that distinct feeling inside of me and the quote of Father Fitzpatrick rang true for me.<br /><br />I know when he has healed enough to trust me again, we will remarry.<br /><br />Don\\'t EVER GET COMPLACENT AND TAKE TRUE LOVE FOR GRANTED! IT HAS BEEN THE HARDEST LESSON OF MY LIFE. <br /><br />Also the music in this movie is OUTSTANDING and MEANINGFUL! This movie is DEEP and spiritually uplifting. TRUE LOVE is worth waiting for, if it is meant to be, it will, no matter what, IT WILL HAPPEN! Nothing is impossible, even when it\\'s the second time around! Thanks!'\n",
            " b'From the first moment, this \"thing\" is just an awful sequence of extremely short cuts of blurry camera work. While the overall plot has every potential for a thriller, the story is so badly told that I\\'m unable to buy it. From the middle of the film, the actions of characters don\\'t make sense to me. Stop reading now to avoid SPOILERS.<br /><br />For instance, Ed\\'s idea to have Edna make coffee for them after having shot off her son\\'s arm is way below his alleged experience; it\\'s just an extremely stupid idea. Domino not questioning the fragmentary orders she receives from Claremont Williams over a breaking-up phone connection just eludes me; shouldn\\'t she be long suspicious that Williams is turning them in? Those FBI agents seem out of their minds showing up with just one single helicopter to something they have every reason to consider a capital mafia shoot-out. Besides, what they do by withholding and leaking information towards Cigliutti is pretty much incitement to murder; it seems to me like farewell to justice if that\\'s they way the FBI does investigations. In reality, they\\'d have a case messed up beyond repair if they acted like this. We get to see a car accident which normally would have at least seriously injured if not killed most of the passengers but miraculously leaves all of them with just a few bruises. Quite the contrary, the accident is immediately followed by Domino making love to Choco, which is from Domino\\'s viewpoint in no way founded by previous events but just by being drugged to the eyeballs.<br /><br />The whole sequence of scenes starting from the phone call of Claremont Williams appears to me just as want-to-be dramatic razzle-dazzle. This combined with the awful, uneasy camera work just makes a piece I hesitate to call a movie. I\\'m sorry for the wasted effort of the main actors, whose talent is out of question.'\n",
            " b\"Kris Kristofferson, at his drugged-out peak in the mid-70s, finds himself barely able to squeeze on to the screen alongside La Streisand's humongous ego and discount-store feminism.<br /><br />None of the characters are really likable; I was _so_ glad when Kristofferson's Ferrari went over that hill and crashed.<br /><br />If you want to see a good movie about rock and roll stardom, try _The Buddy Holly Story_ (made only about a year and a half after this dreck).\"\n",
            " b'I think scarecrows are creepy, so it\\'s a pity this movie doesn\\'t make more of them. <br /><br />A bunch of robbers do an emergency parachute from a plane into a enormous field with scarecrows. One of them goes missing with the loot and so the rest chase him down while being set upon by inexplicably evil scarecrows. The acting is hammy and the scarecrows unimpressive (when they move). On the positive side, the director does get some suspense out of the static scarecrows. It is as Alfred Hitchcock says, \"A bomb under a table goes off, and that\\'s surprise. We know the bomb is under the table but not when it will go off, and that\\'s suspense.\"'\n",
            " b'THE BLOB is a great horror movie, not merely because of the vividly horrific images of its nearly unstoppable, flesh-dissolving title character, but because it features a real societal message. It is, in many ways, a \"feel-good horror film.\" The clever storyline is helped immeasurably by solid performances from the entire cast. The two romantic leads, Steve McQueen and Aneta Corsaut, bring surprising depth and sentimentality to the proceedings. They are misunderstood but very well-meaning young people, and it\\'s very easy to root for them.<br /><br />This is a pro-society movie, and its juvenile delinquent characters cause trouble mainly out of boredom, not out of some malevolent character flaw. Steve McQueen\\'s drag-racing rival almost appears to be an enemy early on in the proceedings, but quickly joins in McQueen\\'s campaign to save the town from the oozing invader once he sees McQueen\\'s seriousness. In this way, a character situation that at first appears to be cartoonish suddenly develops depth and human realism.<br /><br />The authorities\\' initial skepticism of the kids\\' wild claims is proved wrong--and once the threat is acknowledged by all, all conflict within the society disappears. This unification of purpose, and the validation of the \"troublemaking\" teens, becomes official when Aneta Corsaut\\'s father breaks into the school to obtain the fire extinguishers needed to freeze the Blob. On any other day, breaking into the school would be considered an act of vandalism typical of a juvenile delinquent--on this particular day, it is a necessary action performed by an adult authority figure. At this turning point, it is clear that there are no lines of division between the young and the old.<br /><br />This is an unusual film in that it acknowledges the perception of a \"generation gap\" but suggests that it is more imaginary than real, and that given a real crisis, people will naturally band together to restore order. \"The Blob\" is a perfect tonic for the kind of depression that generally comes with a viewing of \"Night of the Living Dead\" (1968).<br /><br />Much has been made of the film\\'s cheap but innovative (and effective!) visual effects. They are undeniably clever. A lot of the gravity-defying tricks we see the Blob perform were achieved with miniature sets designed to be rotated. The camera was typically attached to the sets in a very firmly \"locked down\" position (the lights had to be similarly attached so that the lighting remained steady as the room was turned this way and that). These scenes were often photographed one frame at a time as the room was slowly turned--the silicone blob oozed very slowly and its action needed to be sped up. In a way, this was similar to stop motion photography, but utilizing a blob of silicone rather than an articulated puppet. Even today, the effects are startling and bizarre.<br /><br />A very good film with an exploitative-sounding title, THE BLOB is a must-see.'\n",
            " b\"I really hate this show! I had watched one episode, and I knew this show is really terrible. The story lines are both poorly written and executed and the jokes are really bad...I mean it is just a sh++ty rip-off of Dexter's Laboratory and Johnny Quest, 'bout an obnoxious boy with flamed blond hair with his twin genius sisters and talking dog; a stay-at-home dad and a smart, super-busy mom...Like oh-my-flippin'-God! Their dad is a mother-f**kin' crazy home-maker, isn't that so gay! If my dad is a home-maker, I would personally die! Of shame that is...Really I would.<br /><br />I have nothing else to about this...this travesty but only 3 word; count them 3 words to describe it:<br /><br />\\xc2\\xb7 Lame, \\xc2\\xb7 Stupid, and above all... \\xc2\\xb7 F**K UP! That's all I could say folks, it is definitely making my list of worst animated series EV-ER! If I had one that is.\"\n",
            " b'I just got done watching \"Kalifornia\" on Showtime for the fourth time since I first saw it back in July of 2001. You would think that with the recent wave of serial killer films, that \"Kalifornia\" would be amongst some of the earlier films worthy of mention but hasn\\'t. Perhaps if this film had been released sometime between like 1996-1999, maybe it might have been more successful. In my opinion, \"Kalifornia\" is much different from most serial killer films released during the late 1990s. It has an almost completely different atmosphere from most of today\\'s serial killer films like \"Seven\" or \"The Bone Collector\". Many serial killer films have shown a killer but that person is always behind a mask or we never see enough of them to actually learn anything about them. \"Kalifornia\" is a film that actually tries to break through that barrier and actually understand the criminal mind. It tries to answer questions like \"why do they do the things they do? Is it because of something that happened in their past? Does it make them feel superior or powerful? Or do they do it because they like the thrill of the kill?\" These are some of the things that \"Kalifornia\" tries to answer but also leaves room for us to try and figure things out for ourselves. Brad Pitt makes an everlasting impression as Early Grayce. When we first meet Early in the beginning of the film, we see that he is obviously one disturbed individual. When we first see him, it\\'s late at night. Early is possibly drunk. We then see him pick up a rock, throw it off a bridge, and it later lands on the windshield of a passing car. Pitt is fierce in this film. It is always good to see him when he plays psychos or really bad people. It\\'s funny that this would later lead him play a true loon like in \"12 Monkeys\" and that he would be on the other end of the spectrum in David Fincher\\'s \"Seven\".'], shape=(32,), dtype=string)\n",
            "tf.Tensor([0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NLLOMKd5H0NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JYoM_p4FoLO"
      },
      "source": [
        "**Inspecting the output of our binary unigram dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8ZsoFNisFoLO",
        "outputId": "a9c34ebf-0de7-4066-f4d6-06a3f6aab349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUq2cfpgFoLO"
      },
      "source": [
        "**Our model-building utility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "J8ufplgwFoLO"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBuy9PxCFoLO"
      },
      "source": [
        "**Training and testing the binary unigram model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5NuwMLpHFoLP",
        "outputId": "cc01c350-9758-47df-e3a1-e7e9bcb6a6ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 11s 13ms/step - loss: 0.4333 - accuracy: 0.8184 - val_loss: 0.3031 - val_accuracy: 0.8760\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2961 - accuracy: 0.8957 - val_loss: 0.2944 - val_accuracy: 0.8756\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2684 - accuracy: 0.9057 - val_loss: 0.2913 - val_accuracy: 0.8826\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2516 - accuracy: 0.9129 - val_loss: 0.3024 - val_accuracy: 0.8780\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2490 - accuracy: 0.9143 - val_loss: 0.3142 - val_accuracy: 0.8716\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2417 - accuracy: 0.9204 - val_loss: 0.3229 - val_accuracy: 0.8778\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2400 - accuracy: 0.9200 - val_loss: 0.3350 - val_accuracy: 0.8740\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2321 - accuracy: 0.9235 - val_loss: 0.3380 - val_accuracy: 0.8732\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2299 - accuracy: 0.9222 - val_loss: 0.3472 - val_accuracy: 0.8696\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2287 - accuracy: 0.9229 - val_loss: 0.3518 - val_accuracy: 0.8684\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3024 - accuracy: 0.8826\n",
            "Test acc: 0.883\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0lKKXNeFoLP"
      },
      "source": [
        "#### Bigrams with binary encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko3rEabVFoLP"
      },
      "source": [
        "**Configuring the `TextVectorization` layer to return bigrams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Cmsl2EjOFoLQ"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7kIrfEXFoLQ"
      },
      "source": [
        "**Training and testing the binary bigram model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jh4LEVc3FoLQ",
        "outputId": "d6e50bc5-9aa0-4d50-8181-9dd1ce49314b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 13s 19ms/step - loss: 0.3797 - accuracy: 0.8428 - val_loss: 0.2677 - val_accuracy: 0.8940\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2454 - accuracy: 0.9133 - val_loss: 0.2717 - val_accuracy: 0.8972\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2082 - accuracy: 0.9333 - val_loss: 0.2853 - val_accuracy: 0.8986\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2001 - accuracy: 0.9380 - val_loss: 0.2954 - val_accuracy: 0.8984\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1865 - accuracy: 0.9449 - val_loss: 0.3169 - val_accuracy: 0.9008\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1770 - accuracy: 0.9485 - val_loss: 0.3349 - val_accuracy: 0.8992\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1731 - accuracy: 0.9509 - val_loss: 0.3448 - val_accuracy: 0.8958\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1825 - accuracy: 0.9516 - val_loss: 0.3590 - val_accuracy: 0.8916\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1802 - accuracy: 0.9510 - val_loss: 0.3732 - val_accuracy: 0.8882\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1708 - accuracy: 0.9545 - val_loss: 0.3609 - val_accuracy: 0.8890\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2670 - accuracy: 0.8974\n",
            "Test acc: 0.897\n"
          ]
        }
      ],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkpx-5PoFoLQ"
      },
      "source": [
        "#### Bigrams with TF-IDF encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkRzKisxFoLQ"
      },
      "source": [
        "**Configuring the `TextVectorization` layer to return token counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qzZu_fyWFoLQ"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"count\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXm6bOTMFoLQ"
      },
      "source": [
        "**Configuring `TextVectorization` to return TF-IDF-weighted outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gIRVUYJhFoLR"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxM_GykuFoLR"
      },
      "source": [
        "**Training and testing the TF-IDF bigram model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('CPU'):\n",
        "    text_vectorization.adapt(text_only_train_ds)"
      ],
      "metadata": {
        "id": "ZXrTi7FiM-CF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "k0ITLnWGFoLR",
        "outputId": "5b1ddd93-cf61-43c8-a32c-67d7675a420b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 10s 14ms/step - loss: 0.4928 - accuracy: 0.7710 - val_loss: 0.3095 - val_accuracy: 0.8860\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3352 - accuracy: 0.8583 - val_loss: 0.3151 - val_accuracy: 0.8710\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3210 - accuracy: 0.8636 - val_loss: 0.3172 - val_accuracy: 0.8812\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2991 - accuracy: 0.8756 - val_loss: 0.3284 - val_accuracy: 0.8832\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2891 - accuracy: 0.8834 - val_loss: 0.3432 - val_accuracy: 0.8722\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2683 - accuracy: 0.8933 - val_loss: 0.3425 - val_accuracy: 0.8788\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2450 - accuracy: 0.9011 - val_loss: 0.3739 - val_accuracy: 0.8784\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2483 - accuracy: 0.9003 - val_loss: 0.3772 - val_accuracy: 0.8700\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2340 - accuracy: 0.9050 - val_loss: 0.3709 - val_accuracy: 0.8696\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2302 - accuracy: 0.9067 - val_loss: 0.3821 - val_accuracy: 0.8622\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3097 - accuracy: 0.8874\n",
            "Test acc: 0.887\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "          validation_data=tfidf_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RvpnQW8gFoLR"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "processed_inputs = text_vectorization(inputs)\n",
        "outputs = model(processed_inputs)\n",
        "inference_model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ohb519oIFoLR",
        "outputId": "7daef671-0972-4440-aece-e0bed5adac63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85.98 percent positive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "raw_text_data = tf.convert_to_tensor([\n",
        "    [\"That was an excellent movie, I loved it.\"],\n",
        "])\n",
        "predictions = inference_model(raw_text_data)\n",
        "print(f\"{float(predictions[0] * 100):.2f} percent positive\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chapter11_part01_introduction.i",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}